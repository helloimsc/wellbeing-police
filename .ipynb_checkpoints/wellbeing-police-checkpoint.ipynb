{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wellbeing Police\n",
    "\n",
    "From various subreddit, we have scraped close to 4000 posts. The subreddits include \"r/SuicideWatch\", \"r/BipolarReddit\", \"r/Anxiety\", \"r/AnxietyDepression\", \"r/Depression\", and \"r/Happy\". Each of the subreddit posts currently sitting within its own csv file. We will see what are the fields that are consistent across the CSV files and choose those applicable. Clean up the data, removed the columns not needed. \n",
    "\n",
    "As all the scrapes was created from the same script, the columns of the resulting csv are same across the files. \n",
    "We will proceed to label them according to the subreddit they came from and combine them into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import spacy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Combination and Labeling\n",
    "\n",
    "We retrieved posts in “Hot” section from various subreddits:\n",
    "`r/ptsd`,`r/Anxiety`,`r/SuicideWatch`,`r/depression`,`r/BipolarReddit`,`r/schizophrenia`,`r/EDAnonymous`,`r/EatingDisorders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20725, 3)\n",
      "(18327, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Self Help and Self Care Resources</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>Unfortunately this is a small subreddit and as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Survey thread</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>If you have a survey you would like to share w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PTSD never getting better, don’t want to be al...</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>Made a throwaway account for this obviously.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can’t be bothered with people anymore</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>Why do I have to remind people all the time th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can't stop peeing my pants</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>This is incredibly embarrassing but I am diagn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title subreddit  \\\n",
       "0                  Self Help and Self Care Resources      ptsd   \n",
       "1                                      Survey thread      ptsd   \n",
       "2  PTSD never getting better, don’t want to be al...      ptsd   \n",
       "3            I can’t be bothered with people anymore      ptsd   \n",
       "4                       I can't stop peeing my pants      ptsd   \n",
       "\n",
       "                                                body  \n",
       "0  Unfortunately this is a small subreddit and as...  \n",
       "1  If you have a survey you would like to share w...  \n",
       "2  Made a throwaway account for this obviously.\\n...  \n",
       "3  Why do I have to remind people all the time th...  \n",
       "4  This is incredibly embarrassing but I am diagn...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./reddit/csvs/\"\n",
    "all_csvs = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "all_dfs = []\n",
    "for filename in all_csvs:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    df = df[[\"title\", \"subreddit\", \"body\"]]\n",
    "    \n",
    "    # ## manually remove irrelevant pinned posts\n",
    "    # if df.iloc[0].subreddit in [\"ptsd\",'Anxiety',\"SuicideWatch\",'EDAnonymous']: \n",
    "    #     df=df[2:]\n",
    "    # if df.iloc[0].subreddit in ['BipolarReddit','schizophrenia','EatingDisorders']:\n",
    "    #     df=df[1:]\n",
    "        \n",
    "    all_dfs.append(df)\n",
    "\n",
    "main_df = pd.concat(all_dfs)\n",
    "print(main_df.shape)\n",
    "main_df = main_df.drop_duplicates()\n",
    "print(main_df.shape)\n",
    "main_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few of the subreddit is indicating the same underlying mental problems, we proceed to add an attribute such that these minor differentiation will be grouped for better and easier identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Self Help and Self Care Resources</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>Unfortunately this is a small subreddit and as...</td>\n",
       "      <td>PTSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Survey thread</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>If you have a survey you would like to share w...</td>\n",
       "      <td>PTSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PTSD never getting better, don’t want to be al...</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>Made a throwaway account for this obviously.\\n...</td>\n",
       "      <td>PTSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can’t be bothered with people anymore</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>Why do I have to remind people all the time th...</td>\n",
       "      <td>PTSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can't stop peeing my pants</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>This is incredibly embarrassing but I am diagn...</td>\n",
       "      <td>PTSD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title subreddit  \\\n",
       "0                  Self Help and Self Care Resources      ptsd   \n",
       "1                                      Survey thread      ptsd   \n",
       "2  PTSD never getting better, don’t want to be al...      ptsd   \n",
       "3            I can’t be bothered with people anymore      ptsd   \n",
       "4                       I can't stop peeing my pants      ptsd   \n",
       "\n",
       "                                                body problem  \n",
       "0  Unfortunately this is a small subreddit and as...    PTSD  \n",
       "1  If you have a survey you would like to share w...    PTSD  \n",
       "2  Made a throwaway account for this obviously.\\n...    PTSD  \n",
       "3  Why do I have to remind people all the time th...    PTSD  \n",
       "4  This is incredibly embarrassing but I am diagn...    PTSD  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_problem_mapping = {\n",
    "    \"ptsd\": \"PTSD\",\n",
    "    \"CPTSD\": \"PTSD\",\n",
    "    \"Anxiety\": \"anxiety\",\n",
    "    \"Anxietyhelp\": \"anxiety\",\n",
    "    \"SuicideWatch\": \"suicidal\",\n",
    "    \"selfharm\": \"suicidal\",\n",
    "    \"depression\": \"depression\",\n",
    "    \"depression_help\": \"depression\", \n",
    "    \"BipolarReddit\": \"bipolar\", \n",
    "    \"bipolar\": \"bipolar\",\n",
    "    \"schizophrenia\": \"schizophrenia\",\n",
    "    \"EDAnonymous\": \"eating disorder\",\n",
    "    \"EatingDisorders\": \"eating disorder\",\n",
    "\n",
    "}\n",
    "\n",
    "main_df[\"problem\"] = [sub_problem_mapping[s] for s in main_df[\"subreddit\"]]\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning and Processing\n",
    "- Remove emoticons and non-text characters\n",
    "- Remove excess newline and spacing characters added for emphasis (e.g., poetry paragraphing)\n",
    "- Remove hyperlinks and tags\n",
    "- Change text to lowercase\n",
    "- Simplify punctuation by removing repeated characters (e.g., \"?????\", \"!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_processing import text_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>self help and self care resources</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>unfortunately this is a small subreddit and as...</td>\n",
       "      <td>PTSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>survey thread</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>if you have a survey you would like to share w...</td>\n",
       "      <td>PTSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd never getting better, don’t want to be al...</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>made a throwaway account for this obviously. i...</td>\n",
       "      <td>PTSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i can’t be bothered with people anymore</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>why do i have to remind people all the time th...</td>\n",
       "      <td>PTSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can't stop peeing my pants</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>this is incredibly embarrassing but i am diagn...</td>\n",
       "      <td>PTSD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title subreddit  \\\n",
       "0                  self help and self care resources      ptsd   \n",
       "1                                      survey thread      ptsd   \n",
       "2  ptsd never getting better, don’t want to be al...      ptsd   \n",
       "3            i can’t be bothered with people anymore      ptsd   \n",
       "4                       i can't stop peeing my pants      ptsd   \n",
       "\n",
       "                                                body problem  \n",
       "0  unfortunately this is a small subreddit and as...    PTSD  \n",
       "1  if you have a survey you would like to share w...    PTSD  \n",
       "2  made a throwaway account for this obviously. i...    PTSD  \n",
       "3  why do i have to remind people all the time th...    PTSD  \n",
       "4  this is incredibly embarrassing but i am diagn...    PTSD  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = text_processing()\n",
    "\n",
    "clean_text.process_data(main_df, headers = ['title', 'subreddit', 'body'])\n",
    "\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization with spaCy\n",
    "\n",
    "We use spaCy to perform lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "## Apply further cleaning steps before tokenization\n",
    "def normalize(text): \n",
    "    ## split list symbol with word e.g. -take 2,000mg fish oil\n",
    "    text = re.sub(r\"\\s-([A-Za-z]+)\\b\",r\" - \\1\", text, flags=0)\n",
    "    \n",
    "    ## further split number with word e.g., 6months, 28male, 2hrs\n",
    "    text = re.sub(r\"(\\d+)([A-Za-z]+)\",r\"\\1 \\2\", text, flags=0)\n",
    "    return text\n",
    "    \n",
    "def lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    # Turn it into tokens, ignoring the punctuation\n",
    "    tokens = [token for token in doc if not token.is_punct]\n",
    "    # Convert those tokens into lemmas, EXCEPT the pronouns\n",
    "    lemmas = [token.lemma_ if token.pos_ != 'PRON' else token.orth_ for token in tokens]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply normalize method\n",
    "documents = main_df.body.apply(lambda text: normalize(text))\n",
    "documents = documents.to_list()\n",
    "# labels = main_df.problem.to_list() \n",
    "\n",
    "\n",
    "## Directly apply lemmatize function to documents to get tokenized text\n",
    "# document_lemmatized = [lemmatize(post) for post in documents]\n",
    "# document_lemmatized "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Document-Term Matrices using TF-IDF Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#tfidf_vectorizer = TfidfVectorizer(tokenizer=lemmatize, norm='l1')\n",
    "#matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "#matrix\n",
    "\n",
    "#tokens = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN-Classification\n",
    "\n",
    "#### Create Training & Test Set\n",
    "\n",
    "To evaluate any classifier, we need to split our dataset into a training and a test set. With the method `train_test_split()` this is very easy to do; this method also shuffles the dataset by default, which is important for this example, since the dataset file is ordered with all positive sentences coming first. In the example below, we set the size of the test set to 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of label/class : 7\n",
      "Size of training set: 13663\n",
      "Size of test set: 3416\n"
     ]
    }
   ],
   "source": [
    "sentences = main_df.body\n",
    "labels = main_df.problem\n",
    "num_labels = len(labels.unique()) ##should be 7\n",
    "print(\"Size of label/class : {}\".format(num_labels))\n",
    "\n",
    "# Split sentences and labels into training and test set with a test set size of 20%\n",
    "sentences_train, sentences_test, labels_train, labels_test = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# We can directly convert the numerical class labels from lists to numpy arrays\n",
    "y_train = np.asarray(labels_train)\n",
    "y_test = np.asarray(labels_test)\n",
    "\n",
    "print(\"Size of training set: {}\".format(len(sentences_train)))\n",
    "print(\"Size of test set: {}\".format(len(sentences_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1), max_features=20000)\n",
    "\n",
    "X_train = tfidf_vectorizer.fit_transform(sentences_train)\n",
    "X_test = tfidf_vectorizer.transform(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=num_labels).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precison: 0.095\n",
      "Recall:   0.095\n",
      "F1 score: 0.095\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           PTSD       0.59      0.04      0.07       451\n",
      "        anxiety       1.00      0.00      0.01       525\n",
      "        bipolar       0.00      0.00      0.00       429\n",
      "     depression       0.33      0.05      0.08       572\n",
      "eating disorder       0.48      0.02      0.03       616\n",
      "  schizophrenia       0.08      0.97      0.15       276\n",
      "       suicidal       0.50      0.00      0.01       547\n",
      "\n",
      "       accuracy                           0.10      3416\n",
      "      macro avg       0.43      0.15      0.05      3416\n",
      "   weighted avg       0.46      0.10      0.04      3416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision = metrics.precision_score(y_test, y_pred, average='micro')\n",
    "recall = metrics.recall_score(y_test, y_pred, average='micro')\n",
    "f1 = metrics.f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(\"Precison: {:.3f}\".format(precision))\n",
    "print(\"Recall:   {:.3f}\".format(recall))\n",
    "print(\"F1 score: {:.3f}\".format(f1))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [03:30<00:00, 210.15s/it]\n"
     ]
    }
   ],
   "source": [
    "k_sizes = [7]\n",
    "#k_sizes = [7, 17, 27]\n",
    "\n",
    "max_ngram_size = 1\n",
    "#max_ngram_size = 3\n",
    "num_k = len(k_sizes)\n",
    "\n",
    "# Number runs = number traing/test a KNN classifier\n",
    "num_runs = max_ngram_size * num_k\n",
    "\n",
    "# numpy array to keep track of all results\n",
    "knn_results = np.zeros((max_ngram_size, num_k))\n",
    "\n",
    "with tqdm(total=num_runs) as pbar:\n",
    "    for i, ngram in enumerate(range(1, max_ngram_size+1)):\n",
    "        # Create Document-Term Matrix for different n-gram sizes\n",
    "        tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, ngram), max_features=20000)\n",
    "        X_train = tfidf_vectorizer.fit_transform(sentences_train)\n",
    "        X_test = tfidf_vectorizer.transform(sentences_test)\n",
    "        # Train & test model using cross validation\n",
    "        for j, k in enumerate(k_sizes):\n",
    "            knn = KNeighborsClassifier(n_neighbors=k)\n",
    "            scores = cross_val_score(knn, X_train, y_train, cv=10, scoring=\"f1_micro\")\n",
    "            mean_score = np.mean(scores)\n",
    "            knn_results[i,j] = mean_score\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use the heatmap function from the seaborn package\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(knn_results, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrest\u001b[39m\u001b[38;5;124m\"\u001b[39m, xticklabels\u001b[38;5;241m=\u001b[39mk_sizes, yticklabels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,max_ngram_size\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Use the heatmap function from the seaborn package\n",
    "plt.figure()\n",
    "\n",
    "sns.heatmap(knn_results, annot=True, cmap=\"crest\", xticklabels=k_sizes, yticklabels=list(range(1,max_ngram_size+1)))\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('Maximum N-Gram Size', fontsize=16)\n",
    "plt.xlabel('Number of Neighbors (k)', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "765828f8c836b5785102bc9c70f29a7af25fc7ff828fe3e5bc72b7ce0758f5e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
